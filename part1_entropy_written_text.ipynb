{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6080abd-fd92-416d-b404-25d4edc0e287",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "## Information Theory -- Character Tokens on English Literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877262b9-e62d-4537-bebb-d6f9bcad5e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from text_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb7491f-5fa8-40b6-8001-fae3983bd9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = TextEntropyAnalyzer(max_gram_order=3)\n",
    "classic_texts = get_classic_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec54b0a-331e-4caf-997c-90c4235e8bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Options - \"Pride and Prejudice\", \"Moby Dick\", \"War and Peace\", \"Alice in Wonderland\", \"The Great Gatsby\"\n",
    "text1 = \"War and Peace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d7d73a-0ca9-4b11-a793-56353f1d6caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = analyzer.load_and_analyze_text(classic_texts[text1], text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96b4880-be5a-4f11-881f-ff4eaed35eab",
   "metadata": {},
   "source": [
    "## 1a) Comparing Entropy and Conditional Entropy \n",
    "## Explain the trends you see in the plot_ngram_entropy and plot_cond_entropy functions -- grounded in the mathematical definition of Shannon Entropy and Conditional Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e06eaa-85a0-4d8d-a9b6-b6c400e157be",
   "metadata": {},
   "source": [
    "## Shannon Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605bc11-9689-48cd-8535-63e8a6b2f15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_fig = plot_ngram_entropy(analyzer, text1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4356989-353a-497c-bff4-788ab70aa526",
   "metadata": {},
   "source": [
    "## Conditional Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c5cef0-adaf-4721-9668-2c940d86d18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_chain_fig = plot_cond_entropy(analyzer, text1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d0aab5-0338-4bde-a093-ebce2fb6610e",
   "metadata": {},
   "source": [
    "# 1a Answer - \n",
    "\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4344a595-48de-4cde-ba31-2392ef0f4c0e",
   "metadata": {},
   "source": [
    "## 1b) Entropy Rate\n",
    "\n",
    "### 1b.i)  Briefly describe entropy rate \n",
    "### 1b.ii) What might explain the variation (or lack thereof) between the different estimated entropy rates from characters between different novels? Compare the output of War and Peace to at least one of the other available texts.\n",
    "### 1b.iii) Why might getting a reliable measure of the Entropy Rate for a language be challenging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32256be-f3f4-43b1-ba80-55f1daf69df0",
   "metadata": {},
   "source": [
    "## Entropy Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce012b83-e0af-4ae0-b004-458a29cc74fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_higher_order = TextEntropyAnalyzer(max_gram_order=20)\n",
    "result = analyzer_higher_order.load_and_analyze_text(classic_texts[text1], text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95c556-049f-4046-ab38-a7d0661633a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_entropy_rate_by_order(analyzer_higher_order, text1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba1979f-bee6-4149-916f-1f72b3b479a9",
   "metadata": {},
   "source": [
    "## Entropy Rate -- Alternative Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ec308-4f95-41f9-8bb4-d471312d726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set text 2 to one of the Text Options\n",
    "\n",
    "# Text Options - \"Pride and Prejudice\", \"Moby Dick\", \"Alice in Wonderland\", \"The Great Gatsby\"\n",
    "\n",
    "text2 = \"Second Text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba93c84-b402-4117-b8b8-3568c74f0d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = analyzer_higher_order.load_and_analyze_text(classic_texts[text2], text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c312f-d9a4-42c6-8fa0-51f042795305",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_entropy_rate_by_order(analyzer_higher_order, text2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2f3275-4f10-4536-8925-69763b191a4a",
   "metadata": {},
   "source": [
    "# 1b Answer - \n",
    "\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac613bd-7b4b-4404-8819-3c00415f2372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
